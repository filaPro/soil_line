\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amssymb}
\usepackage{enumitem}
\setlist{nolistsep}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\setlength{\parskip}{0.7em}
\setlength{\parindent}{0em}

\begin{document}

\tableofcontents
\newpage


\section{Введение.}


\section{Постановка задачи.}

\subsection{Постановка задачи классификации.}

\par
Напомним определение задачи классификации. 
Пусть $X$ - множество описаний объектов, $Y$ - конечное множество меток классов, и 
существует неизвестная целевая зависимость - отображение 
$y^\star:\ \mathcal{X} \to \mathcal{Y}$, 
значения которой известны только на конечном подмножестве объектов
$x_1, ..., x_n \in X$. Пары объектов и ответов $(x_i, y_i)$ называют прецендентами.
Совокупность таких пар ${(x_i, y_i)}_{i=1}^n$ называют обучающей выборкой.
\par
Задача обучения по прецендентам заключается в восстановлении зависимости $y^\star$
по заданной обучающей выборк, т.е. в построении решающей функции 
$\mathcal{X} \to \mathcal{Y}$, которая бы
приближала целевую функцию $y^\star(x)$ причем не только на объектах обучающей выборки,
но и на всем множестве $\mathcal{X}$. Кроме того, решающая функция должно допускать эффективную
реализацию на вычислтельой системе.
\par
Каждый объект $x_i$ задается измерениями своих характеристик $f_j(x_i)$, 
которые называют признаками. Таким образом, признаковое описание задается набором функций
$f_j:\ \mathcal{X}\to D_{f_j}$, где $D_{f_j}$ - множество допустимых значений признака.
Выделяют несколько типов признаков в зависимости от множества $D_f$:
\begin{itemize} 
\item бинарный - $D_f=\{0,1\}$
\item номинальный - $D_f$ - конечное множество,
\item порядковый - $D_f$ - конечное упорядоченной множество,
\item количественный - $D_f$ - множество действительных чисел.
\end{itemize}
Пусть признаков $m$ штук, тогда признаковым описание каждого объекта 
$x_i \in \mathcal{X}$ служит вектор $(x_i^1, ..., x_i^m)$. 
Таким образом обучающая выборка представляется в виде совокупности матрицы 
$X \in \mathbb{R}^{n \times m}$ и вектора $Y \in \{1, ..., k\}^n$, где 
$k$ - количество классов.

\subsection{Постановка задачи классификации типов почв по космическим снимкам.}


\section{Предлагаемое решение.}


\subsection{Классификационные модели.}


\subsubsection{Метод ближайших соседей.}


\subsubsection{Случайный лес.}


\subsubsection{Метод опорных векторов.}


\subsubsection{Байесовский классификатор.}


\subsubsection{Логистическая регрессия.}


\subsubsection{Градиентный бустинг.}


\subsection{Настройка классификационной модели.}


\subsubsection{Оценка качества классификации.}


\subsubsection{Оценка важности признаков.}


\subsubsection{Подбор параметров модели.}


\subsection{Данные для экспериментов.}


\subsection{Модель линии почвы.}


\subsection{Предобработка снимков.}


\subsubsection{Фильтрация снимков.}


\subsubsection{Нормализация снимков.}


\subsubsection{Усреднение снимков.}


\subsection{Итоговое признаковое описание объектов.}


\section{Эксперименты.}


\subsection{Используемая вычислительная система.}


\subsection{Классификация по данным почвенных разрезов.}


\subsection{Классификация по данным почвенно карты.}


\section{Заключение.}


\section{Список литературы.}

\end{document}
