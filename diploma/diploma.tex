\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{color}
\usepackage{tabu}
\setlist{nolistsep}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\setlength{\parskip}{0.7em}
\setlength{\parindent}{0em}

\begin{document}

\tableofcontents
\newpage

\section{Введение.}


\section{Постановка задачи.}


\subsection{Постановка задачи классификации.}

\par
Напомним определение задачи классификации. 
Пусть $\mathcal{X}$ - множество описаний объектов, 
$\mathcal{Y}$ - конечное множество меток классов, и 
существует неизвестная целевая зависимость - отображение 
$y^\star:\ \mathcal{X} \to \mathcal{Y}$, 
значения которой известны только на конечном подмножестве объектов
$x_1, ..., x_n \in X$. Пары объектов и ответов $(x_i, y_i)$ называют прецендентами.
Совокупность таких пар ${(x_i, y_i)}_{i=1}^n$ называют обучающей выборкой.
\par
Задача обучения по прецендентам заключается в восстановлении зависимости $y^\star$
по заданной обучающей выборк, т.е. в построении решающей функции 
$\mathcal{X} \to \mathcal{Y}$, которая бы
приближала целевую функцию $y^\star(x)$ причем не только на объектах обучающей выборки,
но и на всем множестве $\mathcal{X}$. Кроме того, решающая функция должно допускать эффективную
реализацию на вычислтельой системе.
\par
Каждый объект $x_i$ задается измерениями своих характеристик $f_j(x_i)$, 
которые называют признаками. Таким образом, признаковое описание задается набором функций
$f_j:\ \mathcal{X}\to D_{f_j}$, где $D_{f_j}$ - множество допустимых значений признака.
Выделяют несколько типов признаков в зависимости от множества $D_f$:
\begin{itemize} 
    \item бинарный - $D_f=\{0,1\}$
    \item номинальный - $D_f$ - конечное множество,
    \item порядковый - $D_f$ - конечное упорядоченной множество,
    \item количественный - $D_f$ - множество действительных чисел.
\end{itemize}
Пусть признаков $m$ штук, тогда признаковым описание каждого объекта 
$x_i \in \mathcal{X}$ служит вектор $(x_i^1, ..., x_i^m)$. 
Таким образом обучающая выборка представляется в виде совокупности матрицы 
$X \in \mathbb{R}^{n \times m}$ и вектора $Y \in \{1, ..., k\}^n$, где 
$k$ - количество классов.

\subsection{Постановка задачи классификации типов почв по космическим снимкам.}

\par
Основной целью данной работы является решение задачи пространственной классификации
по типам почв некоторой территории, заданной набором её космических снимков.
\par
Как было покаано в предыдущем разделе, входными параметрами задачи классификации являются
признаковое пространство объектов, множество меток классов и обучающая выборка выборка,
составленная из пар элементов данных двух множеств. В качестве объектов рассматриваются точки
поверхности Земли, заданные георграфическими координатами. Признаковое пространство определеяется
из данных космических снимков, покрывающих исследуемую территорию. Метки классов берутся
из результатов наземных исследований территории почвоведами.
\par
В данной работе также исследуется информативность некоторых признаков и моделей, 
которые могут быть использованы не только для задачи классификации, 
но и для других приложений из областипочвоведения. 
Подробнее об этом показано в опубликованных автором работах {\color{red}[]}.

\section{Предлагаемое решение.}


\subsection{Классификационные модели.}


\subsubsection{Метод ближайших соседей.}

\par
Метод взвешенных $k$ ближайших соседей - это метрический алгоритм классификации,
основанный на оценивании сходства объектов. Классифицируемый объект относится к тому классу,
к которому принадлежат ближайшие к нему объекты обучающей выборки. Более формально,
пусть на множестве объектов задана функция расстояния $\rho$, например, евклидова:
\[
    \rho(x, x') = \sum_i (x_i - x_i')^2.
\]
Для произвольного объекта $x \in \mathcal{X}$ расположим $k$ его ближайших соседей
из обучающей выборки в порядке возрастания расстояния до 
$x: \rho(x, x_{1;x}) \le \rho(x, x_{2;x}) \le ... \rho(x, x_{k;x})$.
Тогда формула для классификатора будет иметь вид:
\[
    A(x)=\arg\max_{y\in\mathcal{Y}} \sum_{i=1}^k[y_{i;x}=y]w(i, x),
\]
где $w(i, x)$ - заданная весовая функция, оценивающая важность $i$-ого соседа для
классификации объекта $x$. Существует множество эвристик для определения типа $w$,
самые простые из которых это: константная и обратно пропорциональная расстоянию до $i$-ого
объекта. Параметр $k$ данного метода подбирается для каждой задачи индивидуально.

\subsubsection{Случайный лес.}


\subsubsection{Метод опорных векторов.}

\par
Метод SVM (Support vector machine) позволяет разделить объекты двух классов
гиперплоскостью $wx-b=0$ с максимальным отступом между ней и классами.
Вектор $w$ - перпендикуляр к разделяющей гиперплоскости.
Параметр $b$ равен по модулю расстоянию от гиперплоскости до начала координат.
В случае линейной разделимости опорными векторами будут являться ближайшие
к гиперплоскости точки.
Плоскости, параллельные разделяющей и проходящие через опорные вектора классов,
задаются уравнениями $wx-b=1$ и $wx-b=-1$, см. рис. {\color{red} *}.
Ширина максимизируемой полосы между ними равна $\frac{2}{||w||}.$
\par
В реальных задачах классификации не удается гарантировать линейную разделимость классов.
В этом случае вводятся новые переменные $\xi_i \ge 0$, характеризующие велечину ошибки 
на объектах $x_i$. Задача поиска разделяющей гиперплоскости формулируется в виде:
\[\begin{cases}
    \frac{1}{2}||w||^2+C\sum_{i=1}^n\xi_i \to \min_{w, b, \xi_i} \\
    y_i(wx_i-b)\ge 1-\xi_i,\ 1 \le i \le n \\
    \xi_i \ge 0,\ 1 \le i \le n,
\end{cases}\]
где $C$ параметр регуляризации, подбираемый для каждой задачи индивидуально.
\par
По теореме Каруша-Куна-Таккера эта система сводится к эквивалентной задаче
квадратичного программирования:
\[\begin{cases}
    -\sum_{i=1}^n \lambda_i + \frac{1}{2}\sum_{i=1}^n \lambda_i\lambda_j
    y_i y_j (x_i x_j) \to \min_\lambda \\
    0 \le \lambda_i \le C,\ 1 \le i \le n \\
    \sum_{i=1}^n \lambda_i y_i=0.
\end{cases}\]
\par
Дальнейшим развитием метода является использование ядрового перехода вместо
скалярного произведения $x_i$ и $x_j$. При такой замене переменных разделяющая 
гиперплоскость оказывается в пространстве большей размерности, чем исходное, поэтому
разделяющая гиперплоскость в исходном пространстве оказывается не обязательно линейной,
см. рис. {\color{red} *}. Стандартно в SVM используется радиальная базизная функция
в качестве ядра: $k(x_i, x_j)=e^{-\gamma||x_i-x_j||^2}$, с некоторым $\gamma>0$, 
подбирающимся индивидуально для каждой задачи.

\subsubsection{Байесовский классификатор.}

\par
Байесовский классификатор относит объект $x$ к классу $y$, 
вероятность которого для этого объекта максимальна:
\[
    y_i = \arg \max_{y\in\mathcal{Y}} P(y|x).
\]
По теореме Байеса:
\[
    P(y|x)=\frac{P(x|y)P(y)}{P(x)}.
\]
Знаменатель является константой, т.е. не влияет на результат классификации.
Далее, используя предположение о зависимости $x$ только от класса $y$, а не
от других объектов, перепишем числитель:
\[
    P(x_1, ..., x_n|y)P(Y) = P(Y)\prod_i P(x_i|y),
\]
где $x_i$ - признаковое описание объекта $x$. Итоговая формула классификатора имеет вид:
\[
    A(x)=\arg\max_{y\in\mathcal{Y}} P(y)\prod_i P(x_i|y).
\]

\subsubsection{Логистическая регрессия.}


\subsubsection{Градиентный бустинг.}


\subsection{Настройка классификационной модели.}


\subsubsection{Оценка качества классификации.}

\par
Для оценки качества построенных классификационных моделей будет использован стандартный
для данных задач подход - скользящий контроль по $q$ блокам (q-fold cross validation).
Рассмотрим данный метод подробнее. 
Пусть $\mathcal{X}$ - множество описаний объектов, 
$\mathcal{Y}$ - конечное множество меток классов. Заданы конечная обучающая выборка
\[
    X^L=(x_i, y_i)_{i=1}^L \subset \mathcal{X} \times \mathcal{Y} 
\]
и алгоритм обучения - отображение $\mu$, которое
произвольной конечной обучающей выборке $X \subset \mathcal{X}$
ставит в соответствие алгоритм $A:\ X \to \mathcal{Y}$.
Тогда выборка разбивается случаным образом на $q$ непересекающихся блоков размеров
$k_1,...,k_q$:
\[
    X^L=X_1^{k_1} \cup ... \cup X_q^{k_q}
\]
таких, что $k_1+...+k_q=L$. Каждый блок по очереди становится контрольной опдвыборкой,
при этом алгоритм обучения строится по оставшися $q-1$ блокам. Критерий качества
определяется как средняя ошибка на контрольной подвыборке:
\[
    CV(\mu, X^L)=\frac{1}{q}\sum_{n=1}^q Q(\mu(X^L \setminus X_n^{k_n}),X_n^{k_n}),
\]
где $Q(A, X)$ - некоторый функционал качества алгоритма $A$.
\par
В данной работе нас интересует процент правильно определенных меток классов,
поэтому в качестве функционала качества берется точность (accuracy),
определяемую по формуле:
\[
    ACC=\frac{TP+TN}{P+N},
\]
где TP (true positives) - истинно положительные, TN (true negative) - истинно отрицательные,
P (positive) - положительные, N (negative) - отрицательные ответы.
\par
Отдельно стоит рассмотреть способы разбиения обучающей выборки на блоки для скользящего
контроля. Стандартным подходом является равновероятное отнесение каждого примера выборки
к одному из $q$ классов. Однако этот подход может завышать истинное значение функционала
качества, если нам интересна его оценка на выборке, пространственно удалённой от заданной
обучающей. Причиной такого завышения является непрерывность данных, т.е. вероятность 
одинакового ответа двух объектов увеличивается с уменьшением этого расстояния.
Для исследования этого эффекта будем использовать разбиения объектов выборки
(географических точек поверхности Земли) двумя способами: полосами и квадратными блоками.
{\color{red} рис}. Плюсом первого подхода является моделирование оценки качества на
пространственно удаленной территории. Однако для данной задачи при таком разбиении
не для всех классов будут попадать объекты и в обучающую и в контрольную подвыборки.
Этого недостатка не имеет метод с разбиением на квадратные блоки, при правильном
подборе размера стороны такого блока.
\par

\subsubsection{Оценка важности признаков.}


\subsubsection{Подбор гиперпараметров модели.}

\par
Все используемые в работе классификационные модели имеют набор гиперпараметров, подбор которых
необходим для улучшения функционала качества. Оптимальные значения могут отличаться не только
для разных задач машинного обучения, но и на разных подзадачах, возникающих при классификации
типов почв по космическим снимкам. Будем использовать самый простой способ решения этой задачи - 
подбор гиперпараметров по заданнйо сетке. Основным недостатком этого метода являются
временные затраты в случае большого количества комбинаций параметров для перебора.
Однако для задач этой работы это оказывается не критичным. Опишем данный алгоритм подробнее.
\par
Пусть $p_1, ..., p_l$ - список настраеваемых параметров алгоритма обучения $\mu$.
Для каждого $p_i$ из них зададим список возможных значений $p_{i_{min}}, ..., p_{i_{max}}$,
где значения между максимальным и минимальным меняются либо с постоянным,
либо с логарифмическим шагом. Тогда оптимальными значениями $\bar{p_1}, ... \bar{p_l}$
определяются те, которые максимизируют оценку качества на скользящем контроле для
обучающей выобрки $X^L$:
\[
    \{\bar{p_i}\}_{i=1}^l=arg\max_{\{p_i\}} CV(\mu(\{p_i\}_{i=1}^l), X^L).
\]

\subsection{Данные для экспериментов.}

\par
Для исследований были взяты 34 фрагмента кадров спутников Landsat 5, 7, 8 
на территорию Павловского, Арсеньевского и Чернского районо Тульской области Российской Федерации.
Выбор именно этого спутника обусловлен тем, что программа Landsat является наиболее
продолжительным проектом по получению спутниковых снимков планеты. Так первый из спутников
был запущен в 1972 году, а последний на данный момент Landsat 8 - в 2013 году.
В данном исследовании нас интересует открытая поверхность почвы, которая на абсолютном
большинстве снимков исследуемой области покрыта облачным или снежным покровом.
По этой причине из нескольких сотен снимков за указанный промежуток времени были
отобраны только 35 штук, см. таб.\ref{table:scenes}.
\begin{table}[!htbp]
\centering
\begin{tabu}{|l|l|l|}
    \hline
    \multicolumn{1}{|c|}{Номер} & \multicolumn{1}{c|}{Спутник} & \multicolumn{1}{c|}{Дата} \\
    \tabucline[1.5pt]{-} 
           1 & Landsat 5 & 16.05.1985 \\
    \hline 2 & Landsat 5 & 04.08.1985 \\
    \hline 3 & Landsat 5 & 03.05.1986 \\
    \hline 4 & Landsat 5 & 20.06.1986 \\
    \hline 5 & Landsat 5 & 06.07.1986 \\
    \hline 6 & Landsat 5 & 13.12.1986 \\
    \hline 7 & Landsat 5 & 29.10.1987 \\
    \hline 8 & Landsat 5 & 29.09.1988 \\
    \hline 9 & Landsat 5 & 27.05.1989 \\
    \hline 10& Landsat 5 & 14.07.1989 \\
    \hline 11& Landsat 5 & 14.05.1990 \\
    \hline 12& Landsat 5 & 12.07.1994 \\
    \hline 13& Landsat 5 & 29.08.1994 \\
    \hline 14& Landsat 5 & 02.04.1998 \\
    \hline 15& Landsat 5 & 20.05.1998 \\
    \hline 16& Landsat 7 & 06.10.1999 \\
    \hline 17& Landsat 7 & 17.05.2000 \\
    \hline 18& Landsat 7 & 04.05.2001 \\
    \hline 19& Landsat 7 & 23.05.2002 \\
    \hline 20& Landsat 7 & 27.08.2002 \\
    \hline 21& Landsat 7 & 14.10.2002 \\
    \hline 22& Landsat 7 & 26.05.2003 \\
    \hline 23& Landsat 5 & 23.09.2003 \\
    \hline 24& Landsat 5 & 14.08.2006 \\
    \hline 25& Landsat 5 & 17.08.2007 \\
    \hline 26& Landsat 5 & 09.08.2010 \\
    \hline 27& Landsat 5 & 08.05.2011 \\
    \hline 28& Landsat 5 & 27.07.2011 \\
    \hline 29& Landsat 5 & 28.08.2011 \\
    \hline 30& Landsat 8 & 29.03.2014 \\
    \hline 31& Landsat 8 & 20.08.2014 \\
    \hline 32& Landsat 8 & 29.09.2014 \\
    \hline 33& Landsat 8 & 23.10.2014 \\
    \hline 34& Landsat 8 & 16.03.2015 \\
    \hline 35& Landsat 8 & 06.07.2015 \\
    \hline
\end{tabu}
\caption{Список используемых снимков}
\label{table:scenes}
\end{table}

\par
Сами спутники, количество и качество их сенсоров претерпевали изменения на протяжении
программы Landsat. Для дальнейшего понимания приведем таблицу характеристик сенсоров
спутника на примере Landsat 8. {\color{red} таблица}
\par
Для каждой сцены представлены все каналы из таблицы, однако как будет показано ниже, не 
все из них одинаково информативны для задачи классификации типов почв. Основные признаки
будут связаны с тремя цветовыми каналами: Red, Blue, Green, а так же одним инфракрасным: Nir.
Размер всех исследуемых снимков равен 2132 на 2755 пикселей, что соответствует
63960 и 82650 метрам на поверхности Земли соответственно.
\par
Определим так же данные для извлечения меток классов, обязательных для задачи классификации.
В данной используются данные о распространении типов почв из 2 мест:
\begin{itemize}
    \item информация о почвенных разрезах из базы Научно-производственного института по 
        землеустройству, земельному кадастру и технической инвентаризации объектов
        недвижимости,
    \item почвенная карта исследуемой территории, предоставленная Почвенным институтом
        им. В.В. Докучаева.
\end{itemize}
Информация о 1761 почвенном разрезе содержит географические координаты каждого из них,
подробное описание типа почвы и сопутствующую информацию. Из почвенной карты удается
извлечь информацию о типе почв для {\color{red} 1500000} пикселей. Однако данные почвенной
имеют неточности, обусловленые отсутствием жестких границ между типами почвы. Поэтому хотя
для каждого пикселя и записана почва с максимальной по версии строящего карту человека
вероятностью, вероятность встретить там некоторые другие типы почв остается не нулевой.
Другой особенностью данных является иерархичность классификации типов почв.
В данной работе будут использованы типы почв с двух уровней иерархии классификации,
содержащие 3 и 9 классов соответственно, см. таб.\ref{table:soil-types}.
\begin{table}[!htbp]
\centering
\begin{tabu}{|l|l|l|l|}
    \hline
    \multicolumn{2}{|c|}{Класс} & \multicolumn{2}{c|}{Тип почвы} \\
    \hline \multicolumn{1}{|c|}{1-3} & \multicolumn{1}{c|}{1-9} & 
    \multicolumn{1}{c|}{1-3} & \multicolumn{1}{c|}{1-9} \\ 
    \tabucline[1.5pt]{-} 1 & 1 & Дерново-подзолистые & Дерново-сильноподзолистые \\
    \hline 1 & 2 & Дерново-подзолистые & Дерново-среднеподзолистые \\
    \hline 1 & 3 & Дерново-подзолистые & Дерново-слабоподзолистые \\
    \hline 1 & 9 & Дерново-подзолистые & Д.-п. слабодифференцированные \\
    \hline 2 & 4 & Серые лесные & Светло-серые лесные \\
    \hline 2 & 5 & Серые лесные & Серые лесные \\
    \hline 2 & 6 & Серые лесные & Темно-серые лесные \\
    \hline 3 & 7 & Черноземы & Черноземы оподзоленные \\
    \hline 3 & 8 & Черноземы & Черноземы выщелоченные \\
    \hline
\end{tabu}
\caption{Типы почв}
\label{table:soil-types}
\end{table}

\subsection{Модель линии почвы.}

\par
Понятие линия почвы (ЛП) введено и описано в статье {\color{red} []}, как нижняя граница
треугольной области представления снимка в спектральном пространстве Red-Nir.
Переход в указанное спектральное пространство является отображением значений каналов Red и Nir
каждого пикселя в двумерную декартову систему координат, по осям которой отложены эти значения,
см. рис. {\color{red} рис}.
\par
В таком виде линия почвы отделяет область плоскости Red-Nir, соответствующую голой почве, от
остальной части, соответствующей сомкнутому растительному покрову и другим объектам.
Классическая ЛП представляется в виде вытянутого эллипса, разделяющего положительный квадрант
спектральной плоскости Red-Nir на 2 примерно равные части.
\par
С другой стороны, линия почвы является частью математического аппарата расчета
вегетационных индексов. В этом случае линия почвы определяется не как область спектрального
пространства, а как прямая в нем же, задающаяся классическим уравнениес с коэффициентами
$a$ и $b$. В этих подходах линия почвы определяется либо константно, например 
$a=1,\ b=0$ для вегетационного индекса NDVI, либо как прямая, ниже которой нет ни 
одной точки в пространстве Red-Nir {\color{red} []}. Тогда область голой почвы
определяется, как полоса фиксированной ширины над линией почвы.
\par
В приведеных выше вариантах трактовки понятия линии почвы она является характеристикой
конкретного кадра космической съемки. В данной работе используется также линия почвы 
временная (ЛПВ), введенная в {\color{red} []}, см. {\color{red} [рис]}. 
В этом случае линия почвы является совокупностью спектральных значений Red-Nir,
которые принимает во времени однородный участок почвенного покрова, при условии, что
спектральные характеристики получены для открытой поверхности.

\subsection{Предобработка снимков.}

\subsubsection{Фильтрация снимков.}

\par
Для задачи классификации типов почв по набору космических снимков не все пиксели этих снимков
имею одинковую пользу, а некоторые значения мешают построению признаковых описаний. В идеале
для решения задачи необходимо использовать только пиксели, попадающие в облаcть голой почвы
на каждом из снимков. В область голой почвы не входят:
\begin{itemize}
    \item некоторые элементы ландшафта (реки, озера),
    \item снежный покров,
    \item облачный покров,
    \item области вегетирующей в момент съемки растительности,
    \item неприродные объекты (дороги, здания).
\end{itemize}
В данной работе для построения области голой почвы, была использована
модель спектральной окрестности линии почвы, описанная выше в разделе {\color{red} 3.*}.
\par
Построение алгоритма выделения спектральной окрестности линии почвы по распределению 
значений в каналах Red и Nir лежит за пределами исследований данной работы. Известные на данный
момент автоматические алгоритмы построения линии почвы, описанные, например, в {\color{red}[]},
оказываются не применимы в данной задаче, т.к. окрестность не дадается не самим уравнением линии
почвы, ни нимерьшими значениями Red при фиксированных Nir, как предлагается в этой статье.
По этим причинам данный шаг предобработки спутниковых снимков оставлен в полуавтоматическом режиме,
т.е. спектральная окрестность линии почвы выделяется экспертом почвоведом по графику распределения
значений, см. рис. {\color{red}*}.
\par
Заметим так же, что выделенная окрестность однозначно отображается в пространство объектов,
т.е. георафических точек поверхности Земли. Поэтому по той же пространственной области
фильтруются и другие каналы спутниковых снимков: Green, Blue и т.д.

\subsubsection{Нормализация снимков.}

\par
Как было указано в разделе {\color{red} 3.*} данные для исследований содержат спутниковые снимки
одной области за более 15 лет. Такой массив данных порождает проблемы нормализации этих снимков,
т.к. статистические характеристики распределений значений в их каналах существенно различаются.
Эти различия объясняются следующими основными факторами:
\begin{itemize}
    \item различия сенсоров на спутниках разных версий,
    \item различия примененных на спутниках постобработок значений,
    \item различия условий освещения и параметров атмосферы в момент съемки.
\end{itemize}
\par
Единого метода нормализации космических снимков не существует, и для каждой задачи он
подбирается индивидуально. В статье {\color{red}[]} исследуются следующие методы нормализации
для уменьшения отклонений кусочно-линейных аппроксимаций спектральной окрестности 
разных снимков друг от друга:
\begin{itemize}
    \item классическая нормализация (вычитание математического ожидания и деление на дисперсию),
    \item последовательное применение поворота и сдвига,
    \item последовательное применение атмосферной коррекции и сдвига,
    \item атмосферная коррекция,
    \item сдвиг,
    \item поворот,
\item исходные данные (без нормализации).
\end{itemize}
Авторы приходят к выводу, что для данной задачи наилучшие результаты 
показывает классическая нормализация. На рис. {\color{red}* и *} приведены примеры
кусочно-линейных аппроксимаций линии почвы до и после использоваиния нормализации.

\subsubsection{Усреднение снимков.}

Важной проблемой при обработке цифровых снимков является подавление шумов,
неизбежно возникающих из-за несовершеноства снимающего сенсора и условий съемки.
Для подавления шумов используются такие методы как гауссовский, медианный или билатеральный
фильтр. В данной работе будет использоваться медианный фильтр, т.к. он не порождает новых значений,
а заменяет значение пикселя на медианут значений его пространственной окрестности.
Единственным параметром медианной фильтрации является радиус в пикселях пространственной
окрестности. Влияние радиуса усреднения на качество решения задачи классификации будет рассмотрено
а разделе {\color{red} 4.*}.

\subsection{Итоговое признаковое описание объектов.}

Признаковое описание для каждой исследуемой географической точки строится по всем накрывающим
её разноврменным космическим снимкам, прошедших 3 стадии предобработки: фильтрацию,
нормализацию и усреднение. В данной работе признаки берутся из множества статистических
характеристик распределений значений 4 цветовых каналов: Red, Nir, Green, Blue. Дополнительно
признаками являлются коэффициент наклона линии почвы временной и доля выборки, не принадлежащая
маске фильтрации. Приведем формулы вычисления всех 18 используемых признаков. Обозначим 
$M$ - множество индексов снимков, значения которых в данной точке не входит в маску фильтрации.
\begin{align*}
    E_{red} &= \frac{1}{|M|}\sum_{i \in M} red_i \\
    STD_{red} &= \frac{1}{|M|}\sum_{i \in M} (red_i - E_{red})^2 \\
    MIN_{red} &= \min_{i \in M} red_i \\
    MAX_{red} &= \max_{i \in M} red_i \\
\end{align*}
\begin{align*}
    E_{nir} &= \frac{1}{|M|}\sum_{i \in M} nir_i \\
    STD_{nir} &= \frac{1}{|M|}\sum_{i \in M} (nir_i - E_{nir})^2 \\
    MIN_{nir} &= \min_{i \in M} nir_i \\
    MAX_{nir} &= \max_{i \in M} nir_i \\
\end{align*}
\begin{align*}
    E_{green} &= \frac{1}{|M|}\sum_{i \in M} green_i \\
    STD_{green} &= \frac{1}{|M|}\sum_{i \in M} (green_i - E_{green})^2 \\
    MIN_{green} &= \min_{i \in M} green_i \\
    MAX_{green} &= \max_{i \in M} green_i \\
\end{align*}
\begin{align*}
    E_{blue} &= \frac{1}{|M|}\sum_{i \in M} blue_i \\
    STD_{blue} &= \frac{1}{|M|}\sum_{i \in M} (blue_i - E_{blue})^2 \\
    MIN_{blue} &= \min_{i \in M} blue_i \\
    MAX_{blue} &= \max_{i \in M} blue_i \\
\end{align*}
\begin{align*}
    A_{soil\_line} &= \frac{|M|\sum_{i \in M} red_i nir_i - 
                            \sum_{i \in M} red_i \sum_{i \in M} nir_i}
                           {|M|\sum_{i \in M} red_i^2 - 
                            \left(\sum_{i \in M} red_i\right)^2} \\
    N_{mask} &= |M|
\end{align*}

\section{Эксперименты.}


\subsection{Используемая вычислительная система.}


\subsection{Классификация по данным почвенных разрезов.}


\subsection{Классификация по данным почвенно карты.}


\section{Заключение.}


\section{Список литературы.}

\end{document}
