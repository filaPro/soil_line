{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import simplejson\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import skimage.filters.rank\n",
    "import skimage.morphology\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Scene:\n",
    "    def __init__(self, config):\n",
    "        if type(config) == str:\n",
    "            with open(config) as f:\n",
    "                config = simplejson.load(f)\n",
    "        self.config = config\n",
    "\n",
    "    def normalize_img(self, index, channel, norm_type='none', path='solp', radius=0):\n",
    "        img = self.read_image(index, channel, path)\n",
    "        mask = self.read_image(index, 'mask', path)\n",
    "        \n",
    "        # TDB: fix radius support\n",
    "        if radius > 0:\n",
    "            if img.dtype != 'uint8':\n",
    "                img = (img / 64).astype(np.uint16)\n",
    "            img = skimage.filters.rank.median(img, skimage.morphology.disk(radius), mask=mask)\n",
    "            if img.dtype != 'uint8':\n",
    "                img = (img * 64).astype(np.uint16)\n",
    "            # mask = skimage.filters.rank.median(img, skimage.morphology.disk(15))\n",
    "            \n",
    "        if norm_type == 'none':\n",
    "            subtrahend = 0\n",
    "            divider = 1 if img.dtype == 'uint8' else 256\n",
    "        elif norm_type == 'disp':\n",
    "            subtrahend = img[mask == 255].mean()\n",
    "            divider = img[mask == 255].std()\n",
    "        elif norm_type == 'refl':\n",
    "            rad_refl = self.load_rad_refl()\n",
    "            subtrahend = rad_refl['rad_' + channel][index]\n",
    "            divider = rad_refl['refl_' + channel][index]\n",
    "        elif norm_type == 'reflshiftshrink12':\n",
    "            rad_refl = self.load_rad_refl()\n",
    "            subtrahend = img[mask == 255].mean()\n",
    "            if channel == 'red':\n",
    "                divider = rad_refl['refl_red'][index]\n",
    "            elif channel == 'nir':\n",
    "                divider = rad_refl['refl_nir'][index] * np.tan(np.radians(45 + 12))\n",
    "            else:\n",
    "                raise ValueError('Unknown channel for norm type')\n",
    "        elif norm_type == 'reflshiftE':\n",
    "            rad_refl = self.load_rad_refl()\n",
    "            if channel == 'red':\n",
    "                e1 = rad_refl['refl_red'][index]\n",
    "                e2 = rad_refl['refl_nir'][index] * np.tan(np.radians(45 + 12))\n",
    "                k1 = img[mask == 255].mean() - rad_refl['rad_red'][index]\n",
    "                k2 = self.read_image(index, 'nir', path)[mask == 255].mean() - rad_refl['rad_nir'][index]\n",
    "                subtrahend = rad_refl['rad_red'][index] + (k1 / e1 - k2 / e2) / 2 * e1\n",
    "                divider = rad_refl['refl_red'][index]\n",
    "            elif channel == 'nir':\n",
    "                e1 = rad_refl['refl_red'][index]\n",
    "                e2 = rad_refl['refl_nir'][index] * np.tan(np.radians(45 + 12))\n",
    "                k1 = self.read_image(index, 'red', path)[mask == 255].mean() - rad_refl['rad_red'][index]\n",
    "                k2 = img[mask == 255].mean() - rad_refl['rad_nir'][index]\n",
    "                subtrahend = rad_refl['rad_nir'][index] - (k1 / e1 - k2 / e2) / 2 * e2\n",
    "                divider = rad_refl['refl_nir'][index] * np.tan(np.radians(45 + 12))\n",
    "            else:\n",
    "                raise ValueError('Unknown channel for norm type')\n",
    "        else:\n",
    "            raise ValueError('Unknown norm type')\n",
    "            \n",
    "        return (img.astype(np.float) - subtrahend) / divider\n",
    "\n",
    "    def read_image(self, index, channel, path):\n",
    "        return skimage.io.imread(os.path.join(self.config['path'], self.config['paths'][path], channel,\n",
    "                                              self.config['scenes'][index]['path'] + self.config['suffs'][path]))\n",
    "\n",
    "    def calculate_soil_line(self, img_red, img_nir, mask=None):\n",
    "        if mask is None:\n",
    "            x = img_red.reshape((-1,))\n",
    "            y = img_nir.reshape((-1,))\n",
    "        else:\n",
    "            x = img_red[mask == 255]\n",
    "            y = img_nir[mask == 255]\n",
    "        return np.linalg.lstsq(np.vstack([x, np.ones(len(x))]).T, y)[0]\n",
    "    \n",
    "    def make_channel_time_array(self, channel, norm_type='none', path='solp', radius=1):\n",
    "        n_imgs = len(self.config['scenes'])\n",
    "        width = self.config['size']['width']\n",
    "        height = self.config['size']['height']\n",
    "        \n",
    "        if channel == 'mask':\n",
    "            dtype = np.uint8\n",
    "        else:\n",
    "            dtype = np.float\n",
    "        \n",
    "        arr = np.empty((height, width, n_imgs), dtype=dtype)\n",
    "        for i in range(n_imgs):\n",
    "            if channel == 'mask':\n",
    "                arr[:, :, i] = self.read_image(i, channel, path)\n",
    "            else:\n",
    "                arr[:, :, i] = self.normalize_img(i, channel, norm_type, path, radius)\n",
    "        return arr\n",
    "    \n",
    "    def calculate_features(self):\n",
    "        time_arrays = {}\n",
    "        for channel in self.config['features']['use_channels'] + ['mask']:\n",
    "            time_arrays[channel] = self.make_channel_time_array(channel, \n",
    "                                                                self.config['features']['norm_type'],\n",
    "                                                                path = self.config['features']['path'],\n",
    "                                                                radius = self.config['features']['radius'])\n",
    "        for channel in self.config['features']['use_channels']:\n",
    "            time_arrays[channel][time_arrays['mask'] == 0] = np.nan\n",
    "        n_nonzero = np.count_nonzero(time_arrays['mask'], axis=2)\n",
    "        \n",
    "        res = []\n",
    "        for f in self.config['features']['features']:\n",
    "            if f['name'] == 'mean':\n",
    "                res.append(np.nanmean(time_arrays[f['channel']], axis=2))\n",
    "            elif f['name'] == 'min':\n",
    "                res.append(np.nanmin(time_arrays[f['channel']], axis=2))\n",
    "            elif f['name'] == 'max':\n",
    "                res.append(np.nanmax(time_arrays[f['channel']], axis=2))\n",
    "            elif f['name'] == 'std':\n",
    "                res.append(np.nanstd(time_arrays[f['channel']], axis=2))\n",
    "            elif f['name'] == 'soil_line_a':\n",
    "                red_mean = np.nanmean(time_arrays['red'], axis=2)\n",
    "                nir_mean = np.nanmean(time_arrays['nir'], axis=2)\n",
    "                red_var = np.nanvar(time_arrays['red'], axis=2)\n",
    "                red_nir_mult = np.nanmean(time_arrays['red'] * time_arrays['nir'], axis=2)\n",
    "                res.append((red_nir_mult - red_mean * nir_mean) / red_var)\n",
    "            elif f['name'] == 'n_nonzero':\n",
    "                res.append(n_nonzero)\n",
    "            else:\n",
    "                raise ValueError('Unknown feature name')\n",
    "        res = np.transpose(np.array(res), [1, 2, 0])\n",
    "        res[n_nonzero < self.config['features']['n_nonzero_limit']] = np.nan\n",
    "        return res\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        feature_names = []\n",
    "        for f in self.config['features']['features']:\n",
    "            name = f['name']\n",
    "            if 'channel' in f.keys():\n",
    "                name += '_' + f['channel']\n",
    "            feature_names.append(name)\n",
    "        return feature_names\n",
    "    \n",
    "    def load_rad_refl(self):\n",
    "        return pd.read_csv(os.path.join(self.config['path'], self.config['paths']['docs'],\n",
    "                                        self.config['docs']['rad_refl']))\n",
    "    \n",
    "    def load_soil_cuts(self):\n",
    "        cuts = pd.read_csv(os.path.join(self.config['path'], self.config['paths']['docs'], \n",
    "                                        self.config['docs']['cuts']))[['col', 'row', 'class']].values\n",
    "        res = np.zeros(A.get_shape(), dtype=np.uint8)\n",
    "        res[cuts[:, 1], cuts[:, 0]] = cuts[:, 2]\n",
    "        return res\n",
    "    \n",
    "    def load_soil_map(self):\n",
    "        return skimage.io.imread(os.path.join(self.config['path'], self.config['paths']['docs'], \n",
    "                                              self.config['docs']['soil_map']))\n",
    "    \n",
    "    def load_gran_map(self):\n",
    "        return skimage.io.imread(os.path.join(self.config['path'], self.config['paths']['docs'], \n",
    "                                              self.config['docs']['gran_map']))\n",
    "    \n",
    "    def get_shape(self):\n",
    "        return (self.config['size']['height'], self.config['size']['width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ElasticClassifier:\n",
    "    def __init__(self, elastic_path, norm_file, centers_file):\n",
    "        self.norm = np.genfromtxt(os.path.join(elastic_path, norm_file), delimiter=',')\n",
    "        self.centers = np.genfromtxt(os.path.join(elastic_path, centers_file), delimiter=',')\n",
    "        self.knn = KNN(n_neighbors=1).fit(self.centers, np.arange(self.centers.shape[0]) + 1)\n",
    "        # print(self.norm)\n",
    "        # print(self.centers)\n",
    "    \n",
    "    def predict(self, features, proba=False):\n",
    "        new_features = np.copy(features)\n",
    "        new_features[:, 1] = features[:, 1] + features[:, 2]\n",
    "        new_features[:, 2] = features[:, 1] - features[:, 2]\n",
    "        new_features -= self.norm[:, 0]\n",
    "        new_features /= self.norm[:, 1]\n",
    "        if not proba:\n",
    "            return self.knn.predict(new_features)\n",
    "        else:\n",
    "            return self.knn.predict_proba(new_features)\n",
    "    \n",
    "    def predict_proba(self, features):\n",
    "        return self.predict(features, proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, features, targets, config):\n",
    "        if type(config) == str:\n",
    "            with open(config) as f:\n",
    "                config = simplejson.load(f)\n",
    "        self._config = config\n",
    "        self.config = config['classifier']\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "        self.x_all = self.features.reshape((-1, self.features.shape[2]))\n",
    "        self.set_classifier()\n",
    "\n",
    "    def generate_train_mask(self):\n",
    "        if self.config['train_mask']['mode'] == 'horizontal':\n",
    "            self.train_mask = np.zeros(self.targets.shape, dtype=np.bool)\n",
    "            params = self.config['train_mask']['params']\n",
    "            size_n = params['size_numerator']\n",
    "            size_d = params['size_denominator']\n",
    "            if size_n == 1:\n",
    "                size = size_n / size_d\n",
    "            elif size_d - size_n == 1:\n",
    "                size = 1 - size_n / size_d\n",
    "            else:\n",
    "                raise ValueError('Invalid size options')\n",
    "            begin = int(params['i'] * size * self.targets.shape[0])\n",
    "            end = int((params['i'] + 1) * size * self.targets.shape[0])\n",
    "            self.train_mask[begin:end, :] = True\n",
    "            if size_n != 1:\n",
    "                self.train_mask = np.logical_not(self.train_mask)\n",
    "        elif self.config['train_mask']['mode'] == 'squares':\n",
    "            self.train_mask = np.zeros(self.targets.shape, dtype=np.bool)\n",
    "            params = self.config['train_mask']['params']\n",
    "            square_size = params['square_size']\n",
    "            shape = self.features.shape\n",
    "            n = (shape[0] // square_size + 1) * (shape[1] // square_size + 1)\n",
    "            size_n = params['size_numerator']\n",
    "            size_d = params['size_denominator']\n",
    "            if size_n == 1:\n",
    "                size = size_n / size_d\n",
    "            elif size_d - size_n == 1:\n",
    "                size = 1 - size_n / size_d\n",
    "            else:\n",
    "                raise ValueError('Invalid size options')\n",
    "            begin = int(params['i'] * size * n)\n",
    "            end = int((params['i'] + 1) * size * n)\n",
    "            arr = np.arange(n)\n",
    "            np.random.seed(params['random_seed'])\n",
    "            np.random.shuffle(arr)\n",
    "            for i in arr[begin:end]:\n",
    "                x_min = i % (shape[1] // square_size + 1) * square_size\n",
    "                x_max = (i % (shape[1] // square_size + 1) + 1) * square_size\n",
    "                y_min = i // (shape[1] // square_size + 1) * square_size\n",
    "                y_max = (i // (shape[1] // square_size + 1) + 1) * square_size\n",
    "                self.train_mask[y_min:y_max, x_min:x_max] = True\n",
    "            if size_n != 1:\n",
    "                self.train_mask = np.logical_not(self.train_mask)\n",
    "        elif self.config['train_mask']['mode'] == 'none':\n",
    "            self.train_mask = np.ones(self.targets.shape, dtype=np.bool)\n",
    "        else:\n",
    "            raise ValueError('Unknown train mask mode')\n",
    "    \n",
    "    def save_train_mask(self):\n",
    "        skimage.io.imsave(os.path.join(self.config['output_path'], 'train_mask.png'), \n",
    "                          self.train_mask.astype(np.uint8) * 255)\n",
    "        \n",
    "    def save_map(self):\n",
    "        if self.config['name'] == 'xgboost':\n",
    "            y_pred = self.clf.predict(xgboost.DMatrix(self.x_all)).astype(np.int)\n",
    "        else:\n",
    "            y_pred = self.clf.predict(np.nan_to_num(self.x_all)).astype(np.int)\n",
    "        y_pred[np.isnan(self.x_all).any(axis=1)] = 0\n",
    "        skimage.io.imsave(os.path.join(self.config['output_path'], 'map.png'),\n",
    "                                       y_pred.reshape(self.features.shape[:2]))\n",
    "        \n",
    "    def save_class_maps(self):\n",
    "        if self.config['name'] == 'xgboost':\n",
    "            y_pred_cl = np.exp(self.clf.predict(xgboost.DMatrix(self.x_all), output_margin=True))\n",
    "        else:\n",
    "            y_pred_cl = self.clf.predict_proba(np.nan_to_num(self.x_all))\n",
    "        y_pred_cl /= np.sum(y_pred_cl, axis=1, keepdims=True)\n",
    "        for i in range(1, y_pred_cl.shape[1]):\n",
    "            y_pred = (y_pred_cl[:, i] * 255).astype(np.uint8)\n",
    "            y_pred[np.isnan(self.x_all).any(axis=1)] = 0\n",
    "            skimage.io.imsave(os.path.join(self.config['output_path'], 'class_map_' + str(i) + '.png'), \n",
    "                              y_pred.reshape(self.features.shape[:2]))\n",
    "    \n",
    "    def normalize_features(self, x):\n",
    "        if x is not None:\n",
    "            return (x - np.nanmean(x, axis=0, keepdims=True)) / np.nanstd(x, axis=0, keepdims=True)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def train_test_all_split(self):        \n",
    "        # self.x_all = self.features.reshape((-1, self.features.shape[2]))\n",
    "        if self.targets != None:\n",
    "            self.y_all = self.targets.reshape((-1,))\n",
    "\n",
    "        xy = np.concatenate([self.features, self.targets.reshape(self.targets.shape + (1,))], axis=2)\n",
    "        xy[xy[:, :, -1] < 1] = np.nan\n",
    "\n",
    "        for t in ['train', 'test']:\n",
    "            if t == 'train':\n",
    "                xy_tmp = np.copy(xy[self.train_mask > 0])\n",
    "                size = self.config['train_size']\n",
    "            else:\n",
    "                xy_tmp = np.copy(xy[self.train_mask <= 0])\n",
    "                size = self.config['test_size']\n",
    "            if size <= 0:\n",
    "                x_tmp, y_tmp = None, None\n",
    "            else:\n",
    "                xy_tmp = xy_tmp[~np.isnan(xy_tmp).any(axis=1)]\n",
    "                xy_tmp = xy_tmp[np.random.choice(xy_tmp.shape[0], min(size, xy_tmp.shape[0]), replace=False)]\n",
    "                x_tmp = xy_tmp[:, :-1]\n",
    "                y_tmp = xy_tmp[:, -1].astype(np.int)\n",
    "            if t == 'train':\n",
    "                self.x_train = np.copy(x_tmp) if x_tmp is not None else None\n",
    "                self.y_train = np.copy(y_tmp) if y_tmp is not None else None\n",
    "            else:\n",
    "                self.x_test = np.copy(x_tmp) if x_tmp is not None else None\n",
    "                self.y_test = np.copy(y_tmp) if y_tmp is not None else None\n",
    "        del xy_tmp, x_tmp, y_tmp\n",
    "        \n",
    "        if self.config['feature_normalization']:\n",
    "            self.x_all = self.normalize_features(self.x_all)\n",
    "            self.x_train = self.normalize_features(self.x_train)\n",
    "            self.x_test = self.normalize_features(self.x_test)\n",
    "    \n",
    "    def set_classifier(self):\n",
    "        if self.config['name'] == 'xgboost':\n",
    "            self.clf = xgboost.Booster()\n",
    "        elif self.config['name'] in ['rfc', 'svm', 'gnb', 'knn', 'lr']:\n",
    "            if self.config['name'] == 'rfc':\n",
    "                self.clf = RFC\n",
    "            elif self.config['name'] == 'svm':\n",
    "                self.clf = SVC\n",
    "            elif self.config['name'] == 'gnb':\n",
    "                self.clf = GNB\n",
    "            elif self.config['name'] == 'knn':\n",
    "                self.clf = KNN\n",
    "            elif self.config['name'] == 'lr':\n",
    "                self.clf = LR\n",
    "            params = self.config['params'][self.config['name']]['params']\n",
    "            self.clf = self.clf(**params)\n",
    "        elif self.config['name'] == 'elastic':\n",
    "            params = self.config['params'][self.config['name']]['params']\n",
    "            elastic_path = os.path.join(self._config['path'],\n",
    "                                        self._config['paths']['docs'], \n",
    "                                        self._config['docs']['elastic'])\n",
    "            self.clf = ElasticClassifier(elastic_path, **params)\n",
    "        else:\n",
    "            raise ValueError('Unknown classifier name')\n",
    "            \n",
    "    def set_grid_search_params(self):\n",
    "        best_params = GridSearchCV(self.clf, self.config['gs_params'], \n",
    "                                   cv=self.config['cv'], n_jobs=2).fit(self.x_train, self.y_train).best_params_\n",
    "        print('best params:', best_params)\n",
    "        self.clf.set_params(**best_params)\n",
    "            \n",
    "    def train(self):\n",
    "        if self.config['name'] == 'xgboost':\n",
    "            self.clf = xgboost.train(self.config['params']['xgboost']['params'], \n",
    "                                     xgboost.DMatrix(self.x_train, label=self.y_train), \n",
    "                                     num_boost_round=self.config['params']['xgboost']['num_boost_round'])\n",
    "        elif self.config['name'] in ['rfc', 'svm', 'gnb', 'knn', 'lr']:\n",
    "            self.clf = self.clf.fit(self.x_train, self.y_train)\n",
    "        else:\n",
    "            raise ValueError('Unknown classifier name')\n",
    "    \n",
    "    def get_feature_importances(self, feature_names=None):\n",
    "        if self.config['name'] == 'xgboost':\n",
    "            if feature_names is None:\n",
    "                mapped = self.clf.get_fscore()\n",
    "            else:\n",
    "                mapper = {'f{0}'.format(i): v for i, v in enumerate(feature_names)}\n",
    "                mapped = {mapper[k]: v for k, v in C.clf.get_fscore().items()}\n",
    "            xgboost.plot_importance(mapped, xlabel=None, ylabel=None)\n",
    "        else:\n",
    "            raise ValueError('Unknown classifier name')\n",
    "            \n",
    "    def get_train_score(self):\n",
    "        return self.get_score(mode='train')\n",
    "        \n",
    "    def get_test_score(self):\n",
    "        return self.get_score(mode='test')\n",
    "        \n",
    "    def get_score(self, mode):\n",
    "        if mode == 'train':\n",
    "            x = self.x_train\n",
    "            y = self.y_train\n",
    "        elif mode == 'test':\n",
    "            x = self.x_test\n",
    "            y = self.y_test\n",
    "        else:\n",
    "            raise ValueError('Unknown mode')\n",
    "        \n",
    "        if x is None or x.size == 0:\n",
    "                raise ValueError('x is None')\n",
    "            \n",
    "        if self.config['name'] == 'xgboost':\n",
    "            x = xgboost.DMatrix(x)\n",
    "        if self.config['scorer_name'] == 'accuracy':\n",
    "            scorer = accuracy_score\n",
    "        else:\n",
    "            raise ValueError('Unknown scorer name')\n",
    "        return scorer(y, self.clf.predict(x).astype(np.int))\n",
    "    \n",
    "    def get_cv_score(self):\n",
    "        if self.config['name'] == 'xgboost':\n",
    "            if self.config['scorer_name'] in ['accuracy', 'merror']:\n",
    "                metrics = {'merror'}\n",
    "            else:\n",
    "                raise ValueError('Unknown scorer for xgboost')\n",
    "            df = xgboost.cv(self.config['params']['xgboost']['params'], \n",
    "                            xgboost.DMatrix(self.x_train, label=self.y_train), \n",
    "                            verbose_eval=bool(self.config['cv_verbose']), \n",
    "                            stratified=True, metrics=metrics, nfold=self.config['cv'], \n",
    "                            num_boost_round=self.config['params']['xgboost']['num_boost_round'])\n",
    "            return 1 - df.values[-1, 0]\n",
    "        elif self.config['name'] in ['rfc', 'svm', 'gnb', 'knn', 'lr']:\n",
    "            return cross_val_score(self.clf, self.x_train, self.y_train, \n",
    "                                   scoring=self.config['scorer_name'],\n",
    "                                   cv=self.config['cv']).mean()\n",
    "        else:\n",
    "            raise ValueError('Unknown classifier name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
